{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph and LangSmith - Agentic RAG Powered by LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdh8CoVWHRvs",
    "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "default_llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "helpfulness_llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lAxaSvlfIeOg"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "\n",
    "tool_belt = [\n",
    "    tavily_tool,\n",
    "    ArxivQueryRun(),\n",
    "]\n",
    "\n",
    "model_with_tools = default_llm.bind_tools(tool_belt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "91flJWtZLUrl"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def call_model(state):\n",
    "  messages = state[\"messages\"]\n",
    "  response = model_with_tools.invoke(messages)\n",
    "  return {\"messages\" : [response]}\n",
    "\n",
    "tool_node = ToolNode(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Agentic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vF4_lgtmQNo",
    "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f3f0be91160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_graph = StateGraph(AgentState)\n",
    "\n",
    "simple_graph.add_node(\"agent\", call_model)\n",
    "simple_graph.add_node(\"action\", tool_node)\n",
    "\n",
    "simple_graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue\n",
    ")\n",
    "\n",
    "simple_graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "simple_graph.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zt9-KS8DpzNx"
   },
   "outputs": [],
   "source": [
    "simple_graph_app = simple_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn4n37PQRPII",
    "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='Technical professionals are using AI in various ways to enhance their work, including automating repetitive tasks, improving decision-making, analyzing large datasets, developing new products and services, and optimizing processes. They leverage AI for tasks such as machine learning model development, natural language processing, computer vision, predictive analytics, and automation of routine operations. This integration of AI helps increase efficiency, accuracy, and innovation across different fields like software development, data analysis, cybersecurity, engineering, and research. Would you like specific examples or insights into particular industries or roles?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 1352, 'total_tokens': 1460, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJDGgcSVmkpiP7UtkjOjxJZiTRJhb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--207533cb-037a-422b-bebc-370292de6edc-0', usage_metadata={'input_tokens': 1352, 'output_tokens': 108, 'total_tokens': 1460, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
    "\n",
    "async for chunk in simple_graph_app.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afv2BuEsV5JG",
    "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LKTiHV0xrYCg50fBoBXJvSIn', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_lowggRGKKCS1NegORGegF9VH', 'function': {'arguments': '{\"query\": \"where does the author of A Comprehensive Survey of Deep Research work\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 1371, 'total_tokens': 1433, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJDGjZt0iGUjvyEHRb0HXMHjVKXq0', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8b7661f1-ca45-49f6-b5a4-975d266781f2-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_LKTiHV0xrYCg50fBoBXJvSIn', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'where does the author of A Comprehensive Survey of Deep Research work'}, 'id': 'call_lowggRGKKCS1NegORGegF9VH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1371, 'output_tokens': 62, 'total_tokens': 1433, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "Tool Used: arxiv\n",
      "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='3d8403d4-a63a-4875-a637-cd046bbfe8ec', tool_call_id='call_LKTiHV0xrYCg50fBoBXJvSIn'), ToolMessage(content='{\"query\": \"where does the author of A Comprehensive Survey of Deep Research work\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://arxiv.org/abs/2506.12594\", \"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"content\": \"View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. By providing a comprehensive framework for understanding Deep Research systems, this survey contributes to both the theoretical understanding of AI-augmented knowledge work and the practical development of more capable, responsible, and accessible research technologies. | Cite as: | arXiv:2506.12594 [cs.AI] | View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\", \"score\": 0.7458619, \"raw_content\": null}, {\"url\": \"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5005162\", \"title\": \"A Comprehensive Survey of Deep Learning Applications in Big Data ...\", \"content\": \"# A Comprehensive Survey of Deep Learning Applications in Big Data Analytics: Trends, Techniques, and Future Directions This survey paper provides valuable insights into the latest trends in the application of deep learning in big data analytics, emphasizing its importance and paving the way for further research and innovation in this dynamic field. Khan, Ayaz H., A Comprehensive Survey of Deep Learning Applications in Big Data Analytics: Trends, Techniques, and Future Directions. We use cookies that are necessary to make our site work. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. #### Functional Cookies These cookies may be set through our site by our advertising partners.\", \"score\": 0.38560653, \"raw_content\": null}, {\"url\": \"https://www.researchgate.net/publication/392735293_A_Comprehensive_Survey_of_Deep_Research_Systems_Methodologies_and_Applications\", \"title\": \"A Comprehensive Survey of Deep Research: Systems ...\", \"content\": \"This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows\", \"score\": 0.37223184, \"raw_content\": null}, {\"url\": \"https://openai.com/index/introducing-deep-research/\", \"title\": \"Introducing deep research - OpenAI\", \"content\": \"Deep research is built for people who do intensive knowledge work in areas like finance, science, policy, and engineering and need thorough,\", \"score\": 0.27941832, \"raw_content\": null}, {\"url\": \"https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856\", \"title\": \"A comprehensive survey of deep learning research on medical ...\", \"content\": \"* Access through\\xa0**your organization** * Patient Access We use cookies that are necessary to make our site work. You can manage your cookie preferences using the “Cookie Settings” link. For more information, see ourCookie Policy We use cookies which are necessary to make our site work. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms.\", \"score\": 0.20343871, \"raw_content\": null}], \"response_time\": 0.74, \"request_id\": \"f97fc752-6267-4162-8059-7e2d6350a269\"}', name='tavily_search', id='87688c5e-6a64-443d-91b7-93fd59737e29', tool_call_id='call_lowggRGKKCS1NegORGegF9VH')]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='The paper titled \"A Comprehensive Survey of Deep Research\" was authored by Renjun Xu and Jingwen Peng. The authors are associated with institutions that are not explicitly mentioned in the search results. Would you like me to try to find their current affiliations through additional searches?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 3078, 'total_tokens': 3132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJDGnwaAPc7jfCMrcd8U4zq7xTEzM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--787f4a45-d666-4312-8cce-49db7cb61569-0', usage_metadata={'input_tokens': 3078, 'output_tokens': 54, 'total_tokens': 3132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
    "\n",
    "async for chunk in simple_graph_app.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        if node == \"action\":\n",
    "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Agentic Graph with LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "orYxBZXSxJjZ",
    "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Deep Research is an AI-powered tool or agent integrated into platforms like ChatGPT that autonomously browses the web, analyzes, and synthesizes information to generate detailed, cited reports on a user-specified topic. It is designed to perform in-depth research by exploring multiple sources over a period of time, typically ranging from 5 to 30 minutes, to provide comprehensive insights and analysis. This tool is useful for conducting thorough investigations on complex topics, producing well-documented reports, and gaining expert-level understanding.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_inputs(input_object):\n",
    "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
    "\n",
    "def parse_output(input_state):\n",
    "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
    "\n",
    "agent_chain_with_formatting = convert_inputs | simple_graph_app | parse_output\n",
    "\n",
    "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CbagRuJop83E"
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
    "    },\n",
    "    {\n",
    "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
    "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RLfrZrgSsn85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['43e2ad32-baaa-44f1-b05a-d186f6c4c630',\n",
       "  'd69e0e63-45e7-446b-8256-86bd0d75cb45'],\n",
       " 'count': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QrAUXMFftlAY"
   },
   "outputs": [],
   "source": [
    "from openevals.llm import create_llm_as_judge\n",
    "from openevals.prompts import CORRECTNESS_PROMPT\n",
    "# print(CORRECTNESS_PROMPT)\n",
    "\n",
    "correctness_evaluator = create_llm_as_judge(\n",
    "        prompt=CORRECTNESS_PROMPT,\n",
    "        model=\"openai:o3-mini\", # very impactful to the final score\n",
    "        feedback_key=\"correctness\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
    "  # determine if the phrases in the reference_outputs are in the outputs\n",
    "  required = reference_outputs.get(\"must_mention\") or []\n",
    "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "efcf57067cf743d8b4ce059a61cbe02e",
      "53e33aae3b97490c82aec7bbb0d6ebba",
      "ad84e0e971d3455db2efe7dd0d1f803e",
      "72adef9b70dd48198b7322b6c5b113cf",
      "8a61d045ffd44ac58f3f13eb10044836",
      "041e22a9b5514e36bd4d1dac01d5d398",
      "886d762f2a7c421382efb5502c6d42a1",
      "ab91fd625bbd43afbf8c6398193a88d0",
      "716557ad09874dcb989d75f7c74424cd",
      "77d4c0ebaae045b58efc4f789c9a2360",
      "0d622ccc56264fac8fd7508dbdbe6e29"
     ]
    },
    "id": "p5TeCUUkuGld",
    "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'simple_agent, baseline-40f875e7' at:\n",
      "https://smith.langchain.com/o/29b9636b-ddfa-4496-93ee-b2875ed2ee09/datasets/a98fb387-c060-4c77-a427-3d0982b0a74b/compare?selectedSessions=13917d7b-ac03-4d92-9690-e3ac515a199c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e0c56259bd42e8b9c4bf13ffe6d747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = client.evaluate(\n",
    "    agent_chain_with_formatting,\n",
    "    data=dataset.name,\n",
    "    evaluators=[correctness_evaluator, must_mention],\n",
    "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
    "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
    "    max_concurrency=4, # optional, add concurrency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhTNe4kWrplB"
   },
   "source": [
    "## Agentic Graph with LLM Helpfulness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HELPFULNESS_PROMPT_TMPL = \"\"\"\\\n",
    "Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
    "\n",
    "Initial Query:\n",
    "{initial_query}\n",
    "\n",
    "Final Response:\n",
    "{final_response}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "z_Sq3A9SaV1O"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def tool_call_or_helpful(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "    return \"action\"\n",
    "\n",
    "  initial_query = state[\"messages\"][0]\n",
    "  final_response = state[\"messages\"][-1]\n",
    "\n",
    "  if len(state[\"messages\"]) > 10:\n",
    "    return \"END\"\n",
    "\n",
    "  helpfullness_prompt_template = PromptTemplate.from_template(HELPFULNESS_PROMPT_TMPL)\n",
    "\n",
    "  helpfulness_chain = helpfullness_prompt_template | helpfulness_llm | StrOutputParser()\n",
    "\n",
    "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
    "\n",
    "  if \"Y\" in helpfulness_response:\n",
    "    return \"end\"\n",
    "  else:\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbDK2MbuREgU",
    "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f3ee0081a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpfulness_graph = StateGraph(AgentState)\n",
    "\n",
    "helpfulness_graph.add_node(\"agent\", call_model)\n",
    "helpfulness_graph.add_node(\"action\", tool_node)\n",
    "\n",
    "helpfulness_graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "helpfulness_graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tool_call_or_helpful,\n",
    "    {\n",
    "        \"continue\" : \"agent\",\n",
    "        \"action\" : \"action\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")\n",
    "\n",
    "helpfulness_graph.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oQldl8ERQ8lf"
   },
   "outputs": [],
   "source": [
    "helpfulness_graph_app = helpfulness_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3oo8E-PRK1T",
    "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ek2plYVa9rIntjcqBvPiRKEp', 'function': {'arguments': '{\"query\":\"Deep Research Agents\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 1347, 'total_tokens': 1365, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJDH7YtkadEwoxisOKPLAqogSodhD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--eed8b2b8-bb20-48b3-ad3f-81515a9af318-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Deep Research Agents'}, 'id': 'call_Ek2plYVa9rIntjcqBvPiRKEp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1347, 'output_tokens': 18, 'total_tokens': 1365, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'action'\n",
      "[ToolMessage(content='{\"query\": \"Deep Research Agents\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://docs.flowiseai.com/tutorials/deep-research\", \"title\": \"Deep Research | FlowiseAI\", \"content\": \"Deep Research Agent is a sophisticated multi-agent system that can conduct comprehensive research on any topic by breaking down complex queries into manageable tasks, deploying specialized research agents, and synthesizing findings into detailed reports. 1. **Planner Agent**: Analyzes the research query and generates a list of specialized research tasks 3. **Research SubAgents**: Individual agents that conduct focused research using web search and other tools 5. **Condition Agent**: Determines if additional research is needed or if the findings are sufficient 4. Planner Agent will look at the current report, and generate additional research tasks. If more is needed, the Planner Agent reviews all messages, identifies areas for improvement, generates follow-up research tasks, and the loop continues.\", \"score\": 0.9363841, \"raw_content\": null}, {\"url\": \"https://blog.langchain.com/deep-agents/\", \"title\": \"Deep Agents\", \"content\": \"# Deep Agents Applications like “Deep Research”, “Manus”, and “Claude Code” have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt. All of the major model providers have an agent for Deep Research and for “async” coding tasks. ## Characteristics of deep agents Claude Code is not an anomaly - most of the best coding or deep research agents have pretty complex system prompts. Without these system prompts, the agents would not be nearly as deep. Claude Code can spawn sub agents. ## Build your deep agent You can easily create your own deep agent by passing in a custom prompt (will be inserted into the larger system prompt as custom instructions), custom tools, and custom subagents.\", \"score\": 0.8170061, \"raw_content\": null}, {\"url\": \"https://aisecuritychronicles.org/a-comparison-of-deep-research-ai-agents-52492ee47ca7\", \"title\": \"A Comparison of Deep Research AI Agents | by Omar Santos\", \"content\": \"# A Comparison of Deep Research AI Agents OpenAI reported that its Deep Research agent, using the o3 model, achieved 26.6% accuracy on Humanity’s Last Exam, a dramatic leap from the ~3% that previous models like GPT-4o and Google’s Grok-2 managed. To understand the landscape, let’s compare **OpenAI’s Deep Research**, **Google’s Gemini Deep Research**, and leading **open-source implementations** on key aspects like architecture, workflow, search strategy, and performance: By contrast, open-source projects often leverage smaller models or multiple components: for example, the OpenDeepResearcher can use Anthropic’s Claude-3.5 (via OpenRouter API) to handle both query generation and content analysis, whereas the Hugging Face *open-deep-research* demo used DeepSeek for reasoning and Python-based tools for web scraping.\", \"score\": 0.80442166, \"raw_content\": null}, {\"url\": \"https://arxiv.org/abs/2506.18096\", \"title\": \"Deep Research Agents: A Systematic Examination And ...\", \"content\": \"[Skip to main content](https://arxiv.org/abs/2506.18096#content) [](https://arxiv.org/IgnoreMe) [Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced) *   [Login](https://arxiv.org/login) *   [Help Pages](https://info.arxiv.org/help) *   [About](https://info.arxiv.org/about) Cite as:[arXiv:2506.18096](https://arxiv.org/abs/2506.18096) [cs.AI] (or [arXiv:2506.18096v2](https://arxiv.org/abs/2506.18096v2) [cs.AI] for this version) **[[v1]](https://arxiv.org/abs/2506.18096v1)** Sun, 22 Jun 2025 16:52:48 UTC (2,188 KB) [](https://arxiv.org/abs/2506.18096)Full-text links: *   [View PDF](https://arxiv.org/pdf/2506.18096) *   [HTML (experimental)](https://arxiv.org/html/2506.18096v2) *   [TeX Source](https://arxiv.org/src/2506.18096) *   [Other Formats](https://arxiv.org/format/2506.18096) [cs](https://arxiv.org/abs/2506.18096?context=cs) *   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2506.18096) Data provided by: [](https://arxiv.org/abs/2506.18096) [![Image 5: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2506.18096&description=Deep%20Research%20Agents:%20A%20Systematic%20Examination%20And%20Roadmap \\\\\"Bookmark on BibSonomy\\\\\")[![Image 6: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2506.18096&title=Deep%20Research%20Agents:%20A%20Systematic%20Examination%20And%20Roadmap \\\\\"Bookmark on Reddit\\\\\") Bibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_ *   [Author](https://arxiv.org/abs/2506.18096) *   [Venue](https://arxiv.org/abs/2506.18096) *   [Institution](https://arxiv.org/abs/2506.18096) *   [Topic](https://arxiv.org/abs/2506.18096) [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html). [Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2506.18096) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))  *   [About](https://info.arxiv.org/about) *   [Help](https://info.arxiv.org/help) *   [Contact](https://info.arxiv.org/help/contact.html) *   [Subscribe](https://info.arxiv.org/help/subscribe) *   [Copyright](https://info.arxiv.org/help/license/index.html) *   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html) *   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\", \"score\": 0.752468, \"raw_content\": null}, {\"url\": \"https://openai.com/index/introducing-deep-research/\", \"title\": \"Introducing deep research\", \"content\": \"Feb 2, 2025—An agent that uses reasoning to synthesize large amounts of online information and complete multi-stepresearchtasks for you.\", \"score\": 0.74563974, \"raw_content\": null}], \"response_time\": 1.5, \"request_id\": \"258920a5-2c77-49a2-b7ed-8c71eb80d770\"}', name='tavily_search', id='3dad61c2-8597-4445-a333-b72cc61b96a7', tool_call_id='call_Ek2plYVa9rIntjcqBvPiRKEp')]\n",
      "\n",
      "\n",
      "\n",
      "Receiving update from node: 'agent'\n",
      "[AIMessage(content='Deep Research Agents are sophisticated multi-agent systems designed to conduct comprehensive research on various topics. They work by breaking down complex queries into manageable tasks, deploying specialized research agents, and synthesizing the findings into detailed reports. These agents typically include components like a Planner Agent, which analyzes the research query and generates specific tasks, and Research SubAgents, which focus on conducting targeted research using web searches and other tools. They also have mechanisms to determine if additional research is needed or if the findings are sufficient. These systems are used to perform in-depth research, often leveraging reasoning and multi-step processes to gather and synthesize information effectively.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 3069, 'total_tokens': 3193, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJDH90ByWnzhDlEXfdplrlhy3N6gW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--44759039-4bc6-4c04-b242-b74aa2f7d87e-0', usage_metadata={'input_tokens': 3069, 'output_tokens': 124, 'total_tokens': 3193, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
    "\n",
    "async for chunk in helpfulness_graph_app.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zkh0YJuCp3Zl",
    "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Engineering is an emerging discipline in AI and cybersecurity that involves strategically designing the inputs, especially prompts, provided to AI systems to influence or control their outputs. It focuses on how framing, tone, structure, and supplemental context shape an AI model’s response. As AI becomes more embedded in business operations, content generation, and decision-making, context engineering is becoming a crucial skill for professionals aiming to maximize accuracy, relevance, and safety in AI-generated results.\n",
      "\n",
      "The concept gained significant attention around early 2023, particularly with the rise of ChatGPT and other large language models, when people started sharing clever prompts and techniques to better control AI outputs. It is considered to be the next evolution beyond prompt engineering, emphasizing the importance of the entire context and system design in AI interactions.\n",
      "\n",
      "\n",
      "\n",
      "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has been trained on a large, general dataset and then further training it on a smaller, task-specific dataset. This process allows the model to specialize in the new task while leveraging the knowledge it has already acquired, leading to improved performance and efficiency.\n",
      "\n",
      "Fine-tuning has been a key component of transfer learning, especially in natural language processing (NLP) and computer vision. It became particularly prominent with the rise of large pre-trained models like BERT, GPT, and other transformer-based architectures, which can be fine-tuned for various applications such as sentiment analysis, question answering, image recognition, and more.\n",
      "\n",
      "As for when it \"broke onto the scene,\" fine-tuning gained widespread attention and became a standard practice in the machine learning community around 2018-2019. This period marked the release and adoption of influential models like BERT (introduced by Google in 2018) and GPT-2 (released by OpenAI in 2019), which demonstrated the effectiveness of fine-tuning pre-trained models for a wide range of tasks. These developments significantly accelerated the adoption of fine-tuning in both research and industry, making it a cornerstone technique in modern AI workflows.\n",
      "\n",
      "Would you like more detailed information on the history or specific models related to fine-tuning?\n",
      "\n",
      "\n",
      "\n",
      "LLM-based agents are artificial intelligence systems that utilize large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like text, and making decisions based on complex inputs. These agents leverage the capabilities of LLMs like GPT-3, GPT-4, and similar models to interact with users, automate processes, and solve problems across different domains.\n",
      "\n",
      "The concept of LLM-based agents started gaining significant attention around 2020-2021, as large language models became more advanced and accessible. The release of OpenAI's GPT-3 in June 2020 marked a major milestone, showcasing the potential of LLMs to be integrated into autonomous agents capable of performing complex language tasks. Since then, the development and deployment of LLM-based agents have rapidly accelerated, becoming a prominent area of research and application in AI.\n",
      "\n",
      "Would you like more detailed information on the history, specific applications, or recent developments in LLM-based agents?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]\n",
    "\n",
    "for pattern in patterns:\n",
    "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
    "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
    "  messages = helpfulness_graph_app.invoke(inputs)\n",
    "  print(messages[\"messages\"][-1].content)\n",
    "  print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "05-our-first-agent-with-langgraph (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
